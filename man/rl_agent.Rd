% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/R6_rl_agent.R
\name{rl_agent}
\alias{rl_agent}
\title{R6 Class representing a new Reinforcement Learning Agent}
\description{
R6 Class representing a new Reinforcement Learning Agent

R6 Class representing a new Reinforcement Learning Agent
}
\details{
Called by \code{\link{rl_new_agent}}.
}
\examples{

## ------------------------------------------------
## Method `rl_agent$set_cues`
## ------------------------------------------------

cue_data_list <- list(
  one = data.frame(
    cue = 1,
    onset = 60,
    offset = 80,
    trial = 1:500),
  two = data.frame(
    cue = 2,
    onset = 70,
    offset = 80,
    trial = 1:500
  )
)

}
\keyword{internal}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{model_type}}{(character) either "tdrl" or "vprl", referencing the
reinforcement learning paradigm to perform the simulation.}

\item{\code{num_trials}}{(numeric) The number of trials to simulate.}

\item{\code{num_episodes}}{(numeric) The number of episodes per trial.}

\item{\code{num_cues}}{(numeric) The number of potential cues interacting with the RL agent.}

\item{\code{gamma}}{(numeric) The temporal discounting factor of the RL agent}

\item{\code{alpha}}{(numeric) The learning rate of the RL agent}

\item{\code{present_cues}}{A three-dimensional array tacking what cues are
present in each episode across all simulated trials}

\item{\code{estimated_value}}{A three dimensional array tracking the estimated
values of each episode across all trials}

\item{\code{reward}}{A matrix tracking experienced rewards in each episode
across all trials}

\item{\code{RPE}}{A matrix tracking the reward prediction errors occuring in}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{rl_agent$new()}}
\item \href{#method-print}{\code{rl_agent$print()}}
\item \href{#method-set_reward}{\code{rl_agent$set_reward()}}
\item \href{#method-set_cues}{\code{rl_agent$set_cues()}}
\item \href{#method-simulate_agent}{\code{rl_agent$simulate_agent()}}
\item \href{#method-get_tidy_pe_data}{\code{rl_agent$get_tidy_pe_data()}}
\item \href{#method-clone}{\code{rl_agent$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Create a new \code{rlAgent} object
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{rl_agent$new(model_type, num_trials, num_episodes, num_cues, gamma, alpha)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{model_type}}{(character) either "tdrl" or "vprl", referencing the
reinforcement learning paradigm to perform the simulation.}

\item{\code{num_trials}}{(numeric) The number of trials to simulate.}

\item{\code{num_episodes}}{(numeric) The number of episodes per trial.}

\item{\code{num_cues}}{(numeric) The number of potential cues interacting with
the RL agent.}

\item{\code{gamma}}{(numeric) The temporal discounting factor of the RL agent}

\item{\code{alpha}}{(numeric) The learning rate of the RL agent}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-print"></a>}}
\if{latex}{\out{\hypertarget{method-print}{}}}
\subsection{Method \code{print()}}{
Printing method for object of class 'rlAgent'.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{rl_agent$print(...)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{...}}{NA; printing function}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-set_reward"></a>}}
\if{latex}{\out{\hypertarget{method-set_reward}{}}}
\subsection{Method \code{set_reward()}}{
Define the onset episode and offset episode of rewards for
each trial
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{rl_agent$set_reward(
  reward_onset,
  reward_offset,
  reward_magnitude,
  keep_reward_structure = FALSE
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{reward_onset}}{(Numeric) The episode number a reward presentation
begins. Either a single number where reward is presented at the same
episode in all simulated trial or a numeric vector of length
\code{num_trials} with reward onset occurring in different episodes.}

\item{\code{reward_offset}}{(Numeric) The episode number a reward presentation
ends. Either a single number where reward is presented at the same
episode in all simulated trial or a numeric vector of length
\code{num_trials} with reward offset occurring in different episodes.}

\item{\code{reward_magnitude}}{(Numeric) The magnitude of the reward. Either a
single number where reward is presented with the same magnitude across
all simulated trials or a numeric vector of length \code{num_trials} with
reward magnitude differing across trials.}

\item{\code{keep_reward_structure}}{(Logical) \code{FALSE} (default) and any
existing reward structure will be replaced when called. \code{TRUE} and the
reward structure will be modified but will not remove previously
defined rewards.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-set_cues"></a>}}
\if{latex}{\out{\hypertarget{method-set_cues}{}}}
\subsection{Method \code{set_cues()}}{
Define the onset episode and offset episode of cues for
each trial
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{rl_agent$set_cues(cue_list, keep_cue_structure = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{cue_list}}{A list of length \code{num_cues} where each element contains a
data frame with columns 'cue', 'onset', 'offset', and 'trial'.}

\item{\code{keep_cue_structure}}{(Logical) \code{FALSE} (default) and any
existing cue structure will be replaced when called. \code{TRUE} and the
cue structure will be modified but will not remove previously
defined cues.}
}
\if{html}{\out{</div>}}
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{cue_data_list <- list(
  one = data.frame(
    cue = 1,
    onset = 60,
    offset = 80,
    trial = 1:500),
  two = data.frame(
    cue = 2,
    onset = 70,
    offset = 80,
    trial = 1:500
  )
)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-simulate_agent"></a>}}
\if{latex}{\out{\hypertarget{method-simulate_agent}{}}}
\subsection{Method \code{simulate_agent()}}{
Simulate the RL Agent
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{rl_agent$simulate_agent()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-get_tidy_pe_data"></a>}}
\if{latex}{\out{\hypertarget{method-get_tidy_pe_data}{}}}
\subsection{Method \code{get_tidy_pe_data()}}{
Convert the agent's simulated reward prediction errors from
a matrix where each row is an episode and each column is a trial to a
dataframe with columns 'trial', 'episode', and 'value'.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{rl_agent$get_tidy_pe_data(add_trial_zero = TRUE, trial_zero_value = 0)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{add_trial_zero}}{(Logical) \code{TRUE} by default and trial zero will be
appended to the prediction error data frame with values from
\code{trial_zero_value}. \code{FALSE} and output will begin at trial one.}

\item{\code{trial_zero_value}}{(Numeric) Either a single value (default is 0) or
a vector of values to append for trial 0.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A dataframe with the agent's simulated reward prediction errors
('value') for each episode across trials.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{rl_agent$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
