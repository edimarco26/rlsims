% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/R6_kArmedBandit.R
\name{agent_k_armed_bandit}
\alias{agent_k_armed_bandit}
\title{R6 Class representing a K Armed Bandit Agent}
\description{
R6 Class representing a K Armed Bandit Agent

R6 Class representing a K Armed Bandit Agent
}
\details{
Called by \code{\link{rl_new_agent}}.
}
\keyword{internal}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{model_id}}{(character) A model identifier referencing the
reinforcement learning paradigm to perform the simulation.}

\item{\code{num_trials}}{(numeric) The number of trials to simulate.}

\item{\code{num_episodes}}{(numeric) The number of episodes per trial.}

\item{\code{num_arms}}{(numeric) The number of arms (options) the agent can sample from.}

\item{\code{gamma}}{(numeric) The temporal discounting factor of the RL agent}

\item{\code{alpha}}{(numeric) The learning rate of the RL agent}

\item{\code{action_episode}}{(numeric) The episode number in which the agent
takes an action.}

\item{\code{reinforcement_episode}}{(numeric) The episode number in which the
agent receives the reinforcement after taking an action.}

\item{\code{policy}}{(list) A list containing the information relevant to the
agent's decision policy, such as 'softmax' or 'epsilon-greedy' that
guides choice behavior}

\item{\code{actions}}{A numeric vector containing the index of which arm was
selected on a given trial.}

\item{\code{arm_structure}}{A list of arm definitions where each element
contains a data frame with columns 'probability', 'magnitude',
'alternative', and 'trial' describing, respectively, the \code{probability}
of receiving a reward \code{magnitude} with the \code{alternative} for each
\code{trial}.}

\item{\code{Q_values}}{A three dimensional array tracking the estimated Q-value
for selecting each arm across all episodes and trials}

\item{\code{prediction_errors}}{A three dimensional array tracking the
prediction errors associated with choosing each arm across all episodes
and trials}

\item{\code{reinforcements}}{A matrix tracking the experienced reinforcements
associated with choosing an arm across episodes within a given trial}

\item{\code{simulation_code}}{The code for simulating the kArmedBandit}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{agent_k_armed_bandit$new()}}
\item \href{#method-print}{\code{agent_k_armed_bandit$print()}}
\item \href{#method-set_policy}{\code{agent_k_armed_bandit$set_policy()}}
\item \href{#method-set_arms}{\code{agent_k_armed_bandit$set_arms()}}
\item \href{#method-get_arms}{\code{agent_k_armed_bandit$get_arms()}}
\item \href{#method-simulate_agent}{\code{agent_k_armed_bandit$simulate_agent()}}
\item \href{#method-get_learned_values}{\code{agent_k_armed_bandit$get_learned_values()}}
\item \href{#method-get_pe_data}{\code{agent_k_armed_bandit$get_pe_data()}}
\item \href{#method-get_simulation_code}{\code{agent_k_armed_bandit$get_simulation_code()}}
\item \href{#method-clone}{\code{agent_k_armed_bandit$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Create a new \code{kArmedBandit} object
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{agent_k_armed_bandit$new(
  model_id,
  num_trials,
  num_episodes,
  num_arms,
  action_episode,
  reinforcement_episode,
  gamma,
  alpha
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{model_id}}{model_id (character) A model identifier referencing the
reinforcement learning paradigm to perform the simulation.}

\item{\code{num_trials}}{(numeric) The number of trials to simulate.}

\item{\code{num_episodes}}{(numeric) The number of episodes per trial.}

\item{\code{num_arms}}{(numeric) The number of arms (options) the agent can
sample from.}

\item{\code{action_episode}}{(numeric) The episode an action should be taken on.}

\item{\code{reinforcement_episode}}{(numeric) The episode reinforcements should
occur on.}

\item{\code{gamma}}{(numeric) The temporal discounting factor of the RL agent}

\item{\code{alpha}}{(numeric) The learning rate of the RL agent}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-print"></a>}}
\if{latex}{\out{\hypertarget{method-print}{}}}
\subsection{Method \code{print()}}{
Printing method for object of class 'rlAgent'.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{agent_k_armed_bandit$print(...)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{...}}{NA; printing function}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-set_policy"></a>}}
\if{latex}{\out{\hypertarget{method-set_policy}{}}}
\subsection{Method \code{set_policy()}}{
Set an Agent's Action-Selection Policy
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{agent_k_armed_bandit$set_policy(policy, ...)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{policy}}{What policy should a decision be made under? Currently
supported are softmax, greedy, and epsilon-greedy.}

\item{\code{...}}{Additional arguments passed to or from specific methods, such as
\code{tau} when \code{policy = "softmax"} and \code{epsilon} when \code{policy = "epsilonGreedy"}.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-set_arms"></a>}}
\if{latex}{\out{\hypertarget{method-set_arms}{}}}
\subsection{Method \code{set_arms()}}{
Define the arm structure for an agent
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{agent_k_armed_bandit$set_arms(arm_input, keep_arm_structure = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{arm_input}}{A list of arm definitions where each element
contains a data frame with columns 'probability', 'magnitude',
'alternative', and 'trial' describing, respectively, the \code{probability}
of receiving a reward \code{magnitude} with the \code{alternative} for each
\code{trial}.}

\item{\code{keep_arm_structure}}{(Logical) \code{FALSE} (default) and any existing
arm structure will be replaced when called. \code{TRUE} and the arm
structure will be modified but will not remove previously defined
rewards.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-get_arms"></a>}}
\if{latex}{\out{\hypertarget{method-get_arms}{}}}
\subsection{Method \code{get_arms()}}{
Retrieve the list of arm definitions
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{agent_k_armed_bandit$get_arms()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
A list of data frames
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-simulate_agent"></a>}}
\if{latex}{\out{\hypertarget{method-simulate_agent}{}}}
\subsection{Method \code{simulate_agent()}}{
Simulate the RL Agent
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{agent_k_armed_bandit$simulate_agent()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-get_learned_values"></a>}}
\if{latex}{\out{\hypertarget{method-get_learned_values}{}}}
\subsection{Method \code{get_learned_values()}}{
Convert the agent's estimated Q values array where, for each
action, there is an matrix where each row is an episode and each column
is a trial that contains the q_value, to a dataframe with columns
'trial', 'episode', 'action', and 'q_value'.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{agent_k_armed_bandit$get_learned_values(
  add_trial_zero = TRUE,
  trial_zero_value = 0
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{add_trial_zero}}{(Logical) \code{TRUE} by default and trial zero will be
appended to the prediction error data frame with values from
\code{trial_zero_value}. \code{FALSE} and output will begin at trial one.}

\item{\code{trial_zero_value}}{(Numeric) Either a single value (default is 0) or
a vector of values with length \code{num_arms} times \code{num_episodes} to
append for trial 0.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A dataframe with the agent's simulated learned values ('q_value')
from taking an action for each episode across all trials.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-get_pe_data"></a>}}
\if{latex}{\out{\hypertarget{method-get_pe_data}{}}}
\subsection{Method \code{get_pe_data()}}{
Convert the agent's prediction error array where, for each
action, there is an matrix with each row corresponding to an episode
and each column a trial with the experienced prediction error, to a
dataframe with columns 'trial', 'episode', 'action', and 'value'.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{agent_k_armed_bandit$get_pe_data(add_trial_zero = TRUE, trial_zero_value = 0)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{add_trial_zero}}{(Logical) \code{TRUE} by default and trial zero will be
appended to the prediction error data frame with values from
\code{trial_zero_value}. \code{FALSE} and output will begin at trial one.}

\item{\code{trial_zero_value}}{(Numeric) Either a single value (default is 0) or
a vector of values with length \code{num_arms} times \code{num_episodes} to
append for trial 0.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A dataframe with the agent's simulated prediction errors from
taking an action for each episode across all trials.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-get_simulation_code"></a>}}
\if{latex}{\out{\hypertarget{method-get_simulation_code}{}}}
\subsection{Method \code{get_simulation_code()}}{
Retrieve the code needed to simulate the agent.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{agent_k_armed_bandit$get_simulation_code()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{agent_k_armed_bandit$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
