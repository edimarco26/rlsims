% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/func-rl_get_learned_values.R
\name{rl_get_learned_values.kArmedBandit}
\alias{rl_get_learned_values.kArmedBandit}
\title{Get 'kArmedBandit' Agent's Learned Value Data}
\usage{
\method{rl_get_learned_values}{kArmedBandit}(agent, add_trial_zero = TRUE, trial_zero_value = 0, ...)
}
\arguments{
\item{agent}{An object of class "rlAgent" created with
\code{\link{rl_new_agent}}.}

\item{add_trial_zero}{(Logical) \code{TRUE} by default and trial zero will be
appended to the learned value data frame with values from
\code{trial_zero_value}. \code{FALSE} and output will begin at trial one.}

\item{trial_zero_value}{(Numeric) Either a single value (default is 0) or a
vector of values with length \code{num_arms} times \code{num_episodes} to append for
trial 0.}

\item{...}{Additional arguments passed to or from other methods.}
}
\value{
A dataframe with the agent's simulated learned values ('q_value')
from taking an action for each episode across all trials.
}
\description{
Convert the agent's estimated Q values array where, for each
action, there is an matrix where each row is an episode and each column is
a trial that contains the q_value, to a dataframe with columns 'trial',
'episode', 'action', and 'q_value'.
}
