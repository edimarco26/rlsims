% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rl_agent.R
\name{rl_set_reward}
\alias{rl_set_reward}
\title{Setup an agent's Reward Structure}
\usage{
rl_set_reward(
  agent,
  reward_onset,
  reward_offset,
  reward_magnitude,
  keep_reward_structure = FALSE
)
}
\arguments{
\item{agent}{An object of class "rlAgent" created with
\code{\link{rl_new_agent}}.}

\item{reward_onset}{(Numeric) The episode number a reward presentation
begins. Either a single number where reward is presented at the same
episode in all simulated trial or a numeric vector of length \code{num_trials}
with reward onset occurring in different episodes.}

\item{reward_offset}{(Numeric) The episode number a reward presentation ends.
Either a single number where reward is presented at the same episode in all
simulated trial or a numeric vector of length \code{num_trials} with reward
offset occurring in different episodes.}

\item{reward_magnitude}{(Numeric) The magnitude of the reward. Either a
single number where reward is presented with the same magnitude across all
simulated trials or a numeric vector of length \code{num_trials} with reward
magnitude differing across trials.}

\item{keep_reward_structure}{(Logical) \code{FALSE} (default) and any existing
reward structure will be replaced when called. \code{TRUE} and the reward
structure will be modified but will not remove previously defined rewards.}
}
\value{
The agent object with modified reward structure.
}
\description{
Define the onset episode and offset episode of rewards for each
trial
}
